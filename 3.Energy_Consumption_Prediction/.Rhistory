# Eliminating features with no variability
en[, c('year', 'sec')] <- NULL
# Check correlations
correlations <- cor(en)
corrplot(correlations, method = "color", type = "upper",
diag = FALSE, order="FPC", tl.pos = "lt", tl.cex = 0.8)
# Standardize data frame
scaled <- scale(en)
# Find and remove outliers
outliers <- apply(scaled, 1, function(row) any(row > 3 | row < -3))
cleaned_df <- scaled[!outliers, ]
# # Get original mean and sd to revert
original_sd <- apply(en, 2, sd)
original_mean <- colMeans(en)
# Perform PCA
#pca <- prcomp(reverted[,1:29], center = TRUE, scale. = TRUE)
pca <- prcomp(cleaned_df[,1:29])
summary(pca)
# Proportion of variance explained by each principal component
prop_variance <- pca$sdev^2 / sum(pca$sdev^2)
# SCREE Plot of variance explained for each principal component
plot(prop_variance, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Igen values show 14 principal components account for 95.88% of label's variability
components <- 6
# Get values and revert to original scale
standardized_pc <- as.data.frame(pca$x[, 1:components])
reverted_pc <- standardized_pc * original_sd
reverted_pc <- reverted_pc + original_mean
# Create final data frame
#final <- cbind(reverted_pc, reverted[,30])
final <- cbind(reverted_pc, en[,30])
#final <- final %>% rename(consumption = 'reverted[, 30]')
final <- final %>% rename(consumption = 'cleaned_df[, 30]')
# Create final data frame
#final <- cbind(reverted_pc, reverted[,30])
final <- cbind(reverted_pc, cleaned_df[,30])
View(final)
#final <- final %>% rename(consumption = 'reverted[, 30]')
final <- final %>% rename(consumption = 'cleaned_df[, 30]')
# Create train vs test sets
idx <- createDataPartition(final$consumption, p = .8,
list = FALSE,
times = 1)
trData <- final[idx,]
teData <- final[-idx,]
##########  KNN  ##########
trControl <- trainControl(method="cv", number=10)
tuneGrid <- expand.grid(k=10:50)
Knn <- train(consumption ~ ., method = "knn",
trData
,tuneGrid = tuneGrid
,trControl= trControl)
# See best model
Knn
test.features = subset(teData, select=-c(consumption))
test.target = subset(teData, select=consumption)[,1]
# Make predictions
predKnn = predict(Knn, newdata = test.features)
# Evaluate results
# Best model k=40 - R.M.S.E.: 13.18 - Rsquared: 99% - M.A.E.: 3.75
postResample(pred = predKnn, obs = teData$consumption)
trControl <- trainControl(method = "cv", number = 10, search = "grid")
tuneGrid <- expand.grid(.mtry = c(1: 14))
mtryRf <- train(y=trData[,15],
x=trData[, 1:14],
data=trData,
method = "rf",
metric = c("RMSE", "Rsquared"),
tuneGrid = tuneGrid,
trControl = trControl,
importance = TRUE,
ntree = 20)
tuneGrid <- expand.grid(.mtry = c(1: 6))
mtryRf <- train(y=trData[,7],
x=trData[, 1:6],
data=trData,
method = "rf",
metric = c("RMSE", "Rsquared"),
tuneGrid = tuneGrid,
trControl = trControl,
importance = TRUE,
ntree = 20)
rf_model <- randomForest(formula = as.formula(paste(consumption, "~ .")),
data = trData,
ntree = 500,  # Number of trees
mtry = sqrt(ncol(trData)),  # Number of variables randomly sampled as candidates at each split
importance = TRUE)
rf_model <- randomForest(formula = as.formula(paste(trData$consumption, "~ .")),
data = trData,
ntree = 500,  # Number of trees
mtry = sqrt(ncol(trData)),  # Number of variables randomly sampled as candidates at each split
importance = TRUE)
rf_model <- randomForest(formula = as.formula(paste('consumption', "~ .")),
data = trData,
ntree = 500,  # Number of trees
mtry = sqrt(ncol(trData)),  # Number of variables randomly sampled as candidates at each split
importance = TRUE)
predictions <- predict(rf_model, newdata = teData)
# Assess model performance (e.g., using mean squared error)
actual_values <- teData['consumption']
mse <- mean((predictions - actual_values)^2)
# Assess model performance (e.g., using mean squared error)
actual_values <- teData[['consumption']]
mse <- mean((predictions - actual_values)^2)
print(paste("Mean Squared Error:", mse))
RMSE(teData$consumption, predictions)
var_importance <- importance(rf_model)
print(var_importance)
# Calculate R-squared
ss_total <- sum((teData$consumption - mean(teData$consumption))^2)
ss_residual <- sum((teData$consumption - predictions)^2)
rsquared <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", rsquared))
reverted_pc <- standardized_pc * original_sd
library(tidyverse)
library(magrittr)
library(caret)
#library(rpart)
#library(rpart.plot)
library(e1071)
library(corrplot)
library(randomForest)
# Set seed for reproducibility
set.seed(123)
en <- read.csv("energy.csv", header = T)
en <- en %>% relocate('consumption', .after = 'dew')
# Eliminating features with no variability
en[, c('year', 'sec')] <- NULL
# Check correlations
correlations <- cor(en)
corrplot(correlations, method = "color", type = "upper",
diag = FALSE, order="FPC", tl.pos = "lt", tl.cex = 0.8)
# Standardize data frame
scaled <- scale(en)
# Find and remove outliers
outliers <- apply(scaled, 1, function(row) any(row > 3 | row < -3))
cleaned_df <- scaled[!outliers, ]
# # Get original mean and sd to revert
original_sd <- apply(en, 2, sd)
original_mean <- colMeans(en)
reverted <- cleaned_df * original_sd
reverted <- reverted + original_mean
reverted <- as.data.frame(reverted)
# Perform PCA
pca <- prcomp(reverted[,1:29], center = TRUE, scale. = TRUE)
#pca <- prcomp(cleaned_df[,1:29])
summary(pca)
# Proportion of variance explained by each principal component
prop_variance <- pca$sdev^2 / sum(pca$sdev^2)
# SCREE Plot of variance explained for each principal component
plot(prop_variance, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "b")
# Igen values show 14 principal components account for 95.88% of label's variability
components <- 14
# Get values and revert to original scale
standardized_pc <- as.data.frame(pca$x[, 1:components])
reverted_original_sd <- apply(reverted, 2, sd)
reverted_original_mean <- colMeans(reverted)
reverted_pc <- standardized_pc * reverted_original_sd
reverted_pc <- reverted_pc + reverted_original_mean
# Create final data frame
final <- cbind(reverted_pc, reverted[,30])
#final <- cbind(reverted_pc, cleaned_df[,30])
final <- final %>% rename(consumption = 'reverted[, 30]')
# Create train vs test sets
idx <- createDataPartition(final$consumption, p = .8,
list = FALSE,
times = 1)
trData <- final[idx,]
teData <- final[-idx,]
##########  KNN  ##########
trControl <- trainControl(method="cv", number=10)
tuneGrid <- expand.grid(k=10:50)
Knn <- train(consumption ~ ., method = "knn",
trData
,tuneGrid = tuneGrid
,trControl= trControl)
# See best model
Knn
test.features = subset(teData, select=-c(consumption))
test.target = subset(teData, select=consumption)[,1]
# Make predictions
predKnn = predict(Knn, newdata = test.features)
# Evaluate results
# Best model k=49 - R.M.S.E.: 0.62 - Rsquared: 3.9% - M.A.E.: 0.39
postResample(pred = predKnn, obs = teData$consumption)
# M.S.E. baseline: 19747.32
mean((teData$consumption-mean(teData$consumption))^2)
# M.S.E. KNN: 173.77
mean((teData$consumption - predKnn)^2)
ntree_values <- c(50, 100, 150, 200, 500)
mtry <- c(range(1, 14))
mtry <- c(range(14))
?range
mtry <- c(seq(1, 14))
for (i in seq_along(ntree_values)) {
ntree <- ntree_values[i]
# Train the model using a specific ntree value
rf_model <- randomForest(formula = as.formula(paste('consumption', "~ .")),
data = trData,
ntree = ntree,  # Number of trees
mtry = mtry,  # Other parameters
importance = TRUE)
# Predict using the trained model on the test data
predictions <- predict(rf_model, newdata = teData)
# Calculate Mean Squared Error (MSE) for the current ntree value
actual_values <- teData[['consumption']]
mse <- mean((predictions - actual_values)^2)
# Store MSE result for current ntree value
mse_results[i] <- mse
}
mse_results <- numeric(length(ntree_values))
for (i in seq_along(ntree_values)) {
ntree <- ntree_values[i]
# Train the model using a specific ntree value
rf_model <- randomForest(formula = as.formula(paste('consumption', "~ .")),
data = trData,
ntree = ntree,  # Number of trees
mtry = mtry,  # Other parameters
importance = TRUE)
# Predict using the trained model on the test data
predictions <- predict(rf_model, newdata = teData)
# Calculate Mean Squared Error (MSE) for the current ntree value
actual_values <- teData[['consumption']]
mse <- mean((predictions - actual_values)^2)
# Store MSE result for current ntree value
mse_results[i] <- mse
}
# Display MSE results for different ntree values
results <- data.frame(ntree_values, MSE = mse_results)
print(results)
for (i in seq_along(ntree_values)) {
ntree <- ntree_values[i]
# Train the model using a specific ntree value
rf_model <- randomForest(formula = as.formula(paste('consumption', "~ .")),
data = trData,
ntree = ntree,  # Number of trees
mtry = sqrt(ncol(train_data)),  # Other parameters
importance = TRUE)
# Predict using the trained model on the test data
predictions <- predict(rf_model, newdata = teData)
# Calculate Mean Squared Error (MSE) for the current ntree value
actual_values <- teData[['consumption']]
mse <- mean((predictions - actual_values)^2)
# Store MSE result for current ntree value
mse_results[i] <- mse
}
for (i in seq_along(ntree_values)) {
ntree <- ntree_values[i]
# Train the model using a specific ntree value
rf_model <- randomForest(formula = as.formula(paste('consumption', "~ .")),
data = trData,
ntree = ntree,  # Number of trees
mtry = sqrt(ncol(trData)),  # Other parameters
importance = TRUE)
# Predict using the trained model on the test data
predictions <- predict(rf_model, newdata = teData)
# Calculate Mean Squared Error (MSE) for the current ntree value
actual_values <- teData[['consumption']]
mse <- mean((predictions - actual_values)^2)
# Store MSE result for current ntree value
mse_results[i] <- mse
}
# Display MSE results for different ntree values
results <- data.frame(ntree_values, MSE = mse_results)
print(results)
ntree_values <- c(150, 200, 500, 600, 700, 800)
for (i in seq_along(ntree_values)) {
ntree <- ntree_values[i]
# Train the model using a specific ntree value
rf_model <- randomForest(formula = as.formula(paste('consumption', "~ .")),
data = trData,
ntree = ntree,  # Number of trees
mtry = sqrt(ncol(trData)),  # Other parameters
importance = TRUE)
# Predict using the trained model on the test data
predictions <- predict(rf_model, newdata = teData)
# Calculate Mean Squared Error (MSE) for the current ntree value
actual_values <- teData[['consumption']]
mse <- mean((predictions - actual_values)^2)
# Store MSE result for current ntree value
mse_results[i] <- mse
}
mtry_values <- seq(1, 14)
mse_results <- matrix(nrow = length(ntree_values), ncol = length(mtry_values))
mtry_values <- seq(1, 14)
ntree_values <- c(150, 200, 500, 600, 700, 800)
# Iterate through ntree and mtry values and train models
for (i in seq_along(ntree_values)) {
for (j in seq_along(mtry_values)) {
ntree <- ntree_values[i]
mtry <- mtry_values[j]
# Train the model using specific ntree and mtry values
rf_model <- randomForest(formula = as.formula(paste('consumption', "~ .")),
data = trData,
ntree = ntree,  # Number of trees
mtry = mtry,    # Number of variables randomly sampled as candidates at each split
importance = TRUE)
# Predict using the trained model on the test data
predictions <- predict(rf_model, newdata = teData)
# Calculate Mean Squared Error (MSE) for the current ntree and mtry values
actual_values <- teData[['consumption']]
mse <- mean((predictions - actual_values)^2)
# Store MSE result for current ntree and mtry values
mse_results[i, j] <- mse
}
}
# Display MSE results for different ntree and mtry values
colnames(mse_results) <- mtry_values
rownames(mse_results) <- ntree_values
print(mse_results)
for (i in seq_along(ntree_values)) {
ntree <- ntree_values[i]
# Train the model using a specific ntree value
rf_model <- randomForest(formula = as.formula(paste('consumption', "~ .")),
data = trData,
ntree = ntree,  # Number of trees
mtry = sqrt(ncol(trData)),  # Other parameters
importance = TRUE)
# Predict using the trained model on the test data
predictions <- predict(rf_model, newdata = teData)
# Calculate Mean Squared Error (MSE) for the current ntree value
actual_values <- teData[['consumption']]
mse <- mean((predictions - actual_values)^2)
# Store MSE result for current ntree value
mse_results[i] <- mse
}
# Display MSE results for different ntree values
results <- data.frame(ntree_values, MSE = mse_results)
print(results)
# Display MSE results for different ntree and mtry values
colnames(mse_results) <- mtry_values
rownames(mse_results) <- ntree_values
print(mse_results)
# Find the indices of the minimum MSE value in mse_results
min_mse_index <- which(mse_results == min(mse_results), arr.ind = TRUE)
# Extract the ntree and mtry values corresponding to the minimum MSE
best_ntree <- rownames(mse_results)[min_mse_index[1, 1]]
best_mtry <- colnames(mse_results)[min_mse_index[1, 2]]
# Display the combination that yielded the lowest MSE
cat("Best combination - ntree:", best_ntree, "mtry:", best_mtry, "\n")
# Retrain model with best parameters
rf_model <- randomForest(formula = as.formula(paste('consumption', "~ .")),
data = trData,
ntree = 150,
mtry = 8,
importance = TRUE)
predictions <- predict(rf_model, newdata = teData)
# Assess model performance (e.g., using mean squared error)
actual_values <- teData[['consumption']]
mse <- mean((predictions - actual_values)^2)
print(paste("Mean Squared Error:", mse))
# Calculate R-squared
ss_total <- sum((teData$consumption - mean(teData$consumption))^2)
ss_residual <- sum((teData$consumption - predictions)^2)
rsquared <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", rsquared))
RMSE(teData$consumption, predictions)
install.packages("Metrics")
library(Metrics)
mae_value <- mae(predictions, actual_values)
cat("Mean Absolute Error (MAE):", mae_value, "\n")
View(en)
cols <- colnames(en[,1:29])
correlation <- c()
name <- c()
for (col in cols){
name <- c(name, col)
corr <- cor(en$consumption, en[, col])
correlation <- c(correlation, corr)
}
results <- as.data.frame(cbind(name, correlation))
results[abs(correlation)>0.2, ]
results[abs(correlation)>0.1, ]
en %>% ggplot(aes(en$consumption, en$hour))+
+geom_smooth(method = lm)
en %>% ggplot(aes(en$consumption, en$hour))+
geom_smooth(method = lm)
en %>% ggplot(aes(hour, consumption))+
geom_smooth(method = lm)
en %>% ggplot(aes(hour, consumption))+
geom_point()+
geom_smooth(method = lm)
en %>% ggplot(aes(hour, consumption))+
geom_smooth(method = lm)
en %>% ggplot(aes(consumption, hour))+
geom_smooth(method = lm)
en %>% ggplot(aes(hour, consumption))+
geom_smooth(method = lm)
rownames(results[abs(correlation)>0.1, ])
rownames(results[abs(correlation)>0.1, ])[2]
colnames(results[abs(correlation)>0.1, ])[2]
results[abs(correlation)>0.1, ][2]
results[abs(correlation)>0.1, ][1]
results[abs(correlation)>0.1, ][2]
results[abs(correlation)>0.1, ][1]
correlated <- results[abs(correlation)>0.1, ][1]
correlated
plot_scatter <- function(x, consumption) {
en %>% ggplot(aes(x, consumption))+
geom_smooth(method = lm)
}
plot_scatter <- function(x) {
en %>% ggplot(aes(x, consumption))+
geom_smooth(method = lm)
}
for (name in correlated[,2:6]) {
plot_scatter
}
print(correlated)
correlated <- as.data.frame(results[abs(correlation)>0.1, ])[1]
print(correlated)
en %>% ggplot(aes(lights, consumption))+
geom_smooth(method = lm)
en %>% ggplot(aes(Tliving, consumption))+
geom_smooth(method = lm)
en %>% ggplot(aes(Tout, consumption))+
geom_smooth(method = lm)
en %>% ggplot(aes(hOut, consumption))+
geom_smooth(method = lm)
?metrics
?Metrics
??Metrics
# Calculate evaluation metrics
mae_value <- mae(predictions, actual_values)
mse_value <- mse(predictions, actual_values)
rmse_value <- rmse(predictions, actual_values)
r2_value <- r2(predictions, actual_values)
adj_r2_value <- adj_r2(predictions, actual_values)
r_squared <- summary(rf_model)$r.squared
adj_r_squared <- summary(rf_model)$adj.r.squared
# Print the computed metrics
cat("Mean Absolute Error (MAE):", mae_value, "\n")
cat("Mean Squared Error (MSE):", mse_value, "\n")
cat("Root Mean Squared Error (RMSE):", rmse_value, "\n")
knn_mae_value <- mae(predKnn, teData$consumption)
knn_mse_value <- mse(predKnn, teData$consumption)
knn_rmse_value <- rmse(predKnn, teData$consumption)
# Print the computed metrics
cat("Mean Absolute Error (MAE):", knn_mae_value, "\n")
cat("Mean Squared Error (MSE):", knn_mse_value, "\n")
cat("Root Mean Squared Error (RMSE):", knn_rmse_value, "\n")
# Evaluate results
# Best model k=40 - R.M.S.E.: 13.18 - Rsquared: 99% - M.A.E.: 3.75
postResample(pred = predKnn, obs = teData$consumption)
knn_ss_total <- sum((teData$consumption - mean(teData$consumption))^2)
knn_ss_residual <- sum((teData$consumption - predKnn)^2)
knn_rsquared <- 1 - (knn_ss_residual / knn_ss_total)
print(paste("R-squared:", knn_rsquared))
corrplot(correlations, method = "color", type = "upper",
diag = FALSE, order="FPC", tl.pos = "lt", tl.cex = 0.8)
summary(pca)
plot(Knn)
# Display the combination that yielded the lowest MSE
cat("Best combination - ntree:", best_ntree, "mtry:", best_mtry, "\n")
# Find the indices of the minimum MSE value in mse_results
min_mse_index <- which(mse_results == min(mse_results), arr.ind = TRUE)
na(en)
en.na()
is.na(en)
sum(is.na(en))
rf_caret <- train(consumption~.,
data=trData,
method='rf',
trControl=trControl,
tuneGrid=tuneGrid)
tuneGrid <- expand.grid(mtry=c(seq_along(1, 14)),
ntree=c(seq_along(100, 150, 200, 250, 300))
)
seq_along(14)
seq(14)
tuneGrid <- expand.grid(mtry=c(seq(1, 14)),
ntree=c(seq_along(100, 150, 200, 250, 300))
)
tuneGrid <- expand.grid(mtry=c(seq(1, 14)),
ntree=c(100, 150, 200, 250, 300)
)
rf_caret <- train(consumption~.,
data=trData,
method='rf',
trControl=trControl,
tuneGrid=tuneGrid)
ntree_values <- c(100, 150, 200, 250, 300)
mtry_values <- seq(1, 14)
tuneGrid <- expand.grid(mtry = mtry_values, ntree = ntree_values)
rf_caret <- train(consumption~.,
data=trData,
method='rf',
trControl=trControl,
tuneGrid=tuneGrid)
mtry_values <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)
tuneGrid <- expand.grid(mtry = mtry_values, ntree = ntree_values)
rf_caret <- train(consumption~.,
data=trData,
method='rf',
trControl=trControl,
tuneGrid=tuneGrid)
View(trData)
mtry_values <- c(seq(14))
tuneGrid <- expand.grid(mtry = mtry_values, ntree = ntree_values)
tuneGrid <- expand.grid(mtry=c(seq(1, 14)),
ntree=c(100, 150, 200, 250, 300)
)
tuneGrid <- expand.grid(mtry = mtry_values, ntree = ntree_values)
rf_caret <- train(consumption~.,
data=trData,
method='rf',
trControl=trControl,
tuneGrid=tuneGrid)
